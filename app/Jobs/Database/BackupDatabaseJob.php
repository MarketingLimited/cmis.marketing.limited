<?php

namespace App\Jobs\Database;

use Illuminate\Bus\Queueable;
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Foundation\Bus\Dispatchable;
use Illuminate\Queue\InteractsWithQueue;
use Illuminate\Queue\SerializesModels;
use Illuminate\Support\Facades\Log;
use Illuminate\Support\Facades\Storage;
use Carbon\Carbon;

/**
 * Database Backup Job
 *
 * Creates automated backups of PostgreSQL database with:
 * - Compressed dumps (gzip)
 * - Schema-aware backups (per schema or full)
 * - S3 upload support
 * - Local backup retention
 * - Verification after backup
 *
 * Usage:
 * BackupDatabaseJob::dispatch('full')
 * BackupDatabaseJob::dispatch('schema', 'cmis')
 */
class BackupDatabaseJob implements ShouldQueue
{
    use Dispatchable, InteractsWithQueue, Queueable, SerializesModels;

    public $tries = 2;
    public $timeout = 3600; // 1 hour for large databases

    protected string $backupType; // 'full', 'schema', 'data-only'
    protected ?string $schemaName;
    protected bool $uploadToS3;

    /**
     * Create a new job instance.
     *
     * @param string $backupType 'full', 'schema', 'data-only'
     * @param string|null $schemaName Specific schema to backup (optional)
     * @param bool $uploadToS3 Upload to S3 after backup
     */
    public function __construct(
        string $backupType = 'full',
        ?string $schemaName = null,
        bool $uploadToS3 = true
    ) {
        $this->backupType = $backupType;
        $this->schemaName = $schemaName;
        $this->uploadToS3 = $uploadToS3;
    }

    /**
     * Execute the job.
     */
    public function handle(): void
    {
        $startTime = microtime(true);

        Log::info('ðŸ”„ Starting database backup', [
            'type' => $this->backupType,
            'schema' => $this->schemaName,
            'upload_to_s3' => $this->uploadToS3,
        ]);

        try {
            // Generate backup filename
            $filename = $this->generateBackupFilename();
            $backupPath = storage_path("backups/database/{$filename}");

            // Ensure backup directory exists
            $this->ensureBackupDirectory();

            // Create backup
            $this->createBackup($backupPath);

            // Verify backup
            $this->verifyBackup($backupPath);

            // Get backup size
            $backupSize = filesize($backupPath);
            $backupSizeMB = round($backupSize / 1024 / 1024, 2);

            Log::info('âœ… Database backup created successfully', [
                'filename' => $filename,
                'size_mb' => $backupSizeMB,
                'path' => $backupPath,
            ]);

            // Upload to S3 if enabled
            if ($this->uploadToS3 && config('filesystems.disks.s3')) {
                $this->uploadToS3($backupPath, $filename);
            }

            // Clean up old backups (retention policy)
            $this->cleanupOldBackups();

            $duration = round(microtime(true) - $startTime, 2);

            Log::info('âœ… Database backup completed', [
                'filename' => $filename,
                'size_mb' => $backupSizeMB,
                'duration_seconds' => $duration,
            ]);

            // Log to audit table
            $this->logToAudit($filename, $backupSize, $duration);

        } catch (\Exception $e) {
            Log::error('âŒ Database backup failed', [
                'error' => $e->getMessage(),
                'trace' => $e->getTraceAsString(),
            ]);
            throw $e;
        }
    }

    /**
     * Generate backup filename
     */
    protected function generateBackupFilename(): string
    {
        $timestamp = now()->format('Y-m-d_His');
        $type = $this->backupType;
        $schema = $this->schemaName ? "_{$this->schemaName}" : '';

        return "cmis_{$type}{$schema}_{$timestamp}.sql.gz";
    }

    /**
     * Ensure backup directory exists
     */
    protected function ensureBackupDirectory(): void
    {
        $backupDir = storage_path('backups/database');

        if (!file_exists($backupDir)) {
            mkdir($backupDir, 0755, true);
            Log::info('Created backup directory', ['path' => $backupDir]);
        }
    }

    /**
     * Create database backup using pg_dump
     */
    protected function createBackup(string $backupPath): void
    {
        $dbHost = config('database.connections.pgsql.host');
        $dbPort = config('database.connections.pgsql.port', 5432);
        $dbName = config('database.connections.pgsql.database');
        $dbUser = config('database.connections.pgsql.username');
        $dbPassword = config('database.connections.pgsql.password');

        // Build pg_dump command
        $command = $this->buildPgDumpCommand($dbHost, $dbPort, $dbName, $dbUser, $backupPath);

        // Set PGPASSWORD environment variable
        $env = ['PGPASSWORD' => $dbPassword];

        Log::debug('Executing pg_dump', ['command' => preg_replace('/PGPASSWORD=\S+/', 'PGPASSWORD=***', $command)]);

        // Execute backup command
        $output = [];
        $returnCode = 0;

        exec($command, $output, $returnCode);

        if ($returnCode !== 0) {
            throw new \Exception("pg_dump failed with return code {$returnCode}: " . implode("\n", $output));
        }
    }

    /**
     * Build pg_dump command based on backup type
     */
    protected function buildPgDumpCommand(string $host, int $port, string $dbName, string $user, string $backupPath): string
    {
        $baseCommand = "PGPASSWORD='" . addslashes(config('database.connections.pgsql.password')) . "' pg_dump";
        $baseCommand .= " -h {$host} -p {$port} -U {$user}";

        // Add backup type specific options
        switch ($this->backupType) {
            case 'schema':
                if ($this->schemaName) {
                    $baseCommand .= " -n {$this->schemaName}";
                }
                break;

            case 'data-only':
                $baseCommand .= " --data-only";
                if ($this->schemaName) {
                    $baseCommand .= " -n {$this->schemaName}";
                }
                break;

            case 'full':
            default:
                $baseCommand .= " --create --clean";
                break;
        }

        // Add common options
        $baseCommand .= " --no-owner --no-acl";
        $baseCommand .= " {$dbName}";

        // Compress with gzip
        $baseCommand .= " | gzip > {$backupPath}";

        return $baseCommand;
    }

    /**
     * Verify backup integrity
     */
    protected function verifyBackup(string $backupPath): void
    {
        // Check file exists
        if (!file_exists($backupPath)) {
            throw new \Exception("Backup file not created: {$backupPath}");
        }

        // Check file size (should be > 1KB)
        $fileSize = filesize($backupPath);
        if ($fileSize < 1024) {
            throw new \Exception("Backup file too small ({$fileSize} bytes), likely corrupted");
        }

        // Verify gzip integrity
        $command = "gunzip -t {$backupPath} 2>&1";
        exec($command, $output, $returnCode);

        if ($returnCode !== 0) {
            throw new \Exception("Backup file corrupted (gzip verification failed): " . implode("\n", $output));
        }

        Log::info('âœ… Backup verified successfully', ['path' => $backupPath, 'size' => $fileSize]);
    }

    /**
     * Upload backup to S3
     */
    protected function uploadToS3(string $backupPath, string $filename): void
    {
        try {
            Log::info('â˜ï¸ Uploading backup to S3', ['filename' => $filename]);

            $s3Path = "database-backups/" . now()->format('Y/m') . "/{$filename}";

            Storage::disk('s3')->put(
                $s3Path,
                fopen($backupPath, 'r'),
                'private'
            );

            Log::info('âœ… Backup uploaded to S3', ['s3_path' => $s3Path]);

        } catch (\Exception $e) {
            Log::error('âŒ Failed to upload backup to S3', [
                'error' => $e->getMessage(),
                'filename' => $filename,
            ]);
            // Don't throw - local backup still exists
        }
    }

    /**
     * Clean up old backups based on retention policy
     *
     * Retention Policy:
     * - Keep all backups from last 7 days
     * - Keep daily backups from last 30 days
     * - Keep weekly backups from last 90 days
     * - Delete everything older
     */
    protected function cleanupOldBackups(): void
    {
        $backupDir = storage_path('backups/database');
        $files = glob("{$backupDir}/cmis_*.sql.gz");

        if (empty($files)) {
            return;
        }

        $now = now();
        $deleted = 0;

        foreach ($files as $file) {
            $fileTime = Carbon::createFromTimestamp(filemtime($file));
            $ageInDays = $now->diffInDays($fileTime);

            $shouldDelete = false;

            if ($ageInDays > 90) {
                // Delete if older than 90 days
                $shouldDelete = true;
            } elseif ($ageInDays > 30 && $ageInDays <= 90) {
                // Keep only weekly backups (Mon-Sun, keep Monday)
                if ($fileTime->dayOfWeek !== Carbon::MONDAY) {
                    $shouldDelete = true;
                }
            } elseif ($ageInDays > 7 && $ageInDays <= 30) {
                // Keep only daily backups (one per day, keep first one)
                $dateKey = $fileTime->format('Y-m-d');
                // This is simplified - in production, track which daily backup to keep
            }
            // Files <= 7 days: keep all

            if ($shouldDelete) {
                unlink($file);
                $deleted++;
                Log::debug('Deleted old backup', ['file' => basename($file), 'age_days' => $ageInDays]);
            }
        }

        if ($deleted > 0) {
            Log::info("ðŸ—‘ï¸ Cleaned up {$deleted} old backup(s)");
        }
    }

    /**
     * Log backup to audit table
     */
    protected function logToAudit(string $filename, int $backupSize, float $duration): void
    {
        try {
            \Illuminate\Support\Facades\DB::table('cmis_audit.logs')->insert([
                'event_type' => 'database_backup',
                'event_source' => 'BackupDatabaseJob',
                'description' => "Database backup created: {$filename}",
                'metadata' => json_encode([
                    'filename' => $filename,
                    'backup_type' => $this->backupType,
                    'schema' => $this->schemaName,
                    'size_bytes' => $backupSize,
                    'size_mb' => round($backupSize / 1024 / 1024, 2),
                    'duration_seconds' => $duration,
                    'uploaded_to_s3' => $this->uploadToS3,
                ]),
                'created_at' => now(),
            ]);
        } catch (\Exception $e) {
            Log::warning("Failed to log backup to audit table: {$e->getMessage()}");
        }
    }

    /**
     * Handle job failure
     */
    public function failed(\Throwable $exception): void
    {
        Log::error('âŒ Database backup job failed', [
            'error' => $exception->getMessage(),
            'trace' => $exception->getTraceAsString(),
        ]);
    }
}
